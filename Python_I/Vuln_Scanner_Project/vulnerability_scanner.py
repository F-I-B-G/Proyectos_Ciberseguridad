# vulnerability_scanner.py
import json
import sqlite3
from concurrent.futures import ThreadPoolExecutor, as_completed
from rich.console import Console
from rich.table import Table
from bs4 import BeautifulSoup
from utils.http_client import safe_get
from config_loader import load_config
import os
from typing import List, Dict

DB_PATH = "cache.db"

class VulnerabilityScanner:
    def __init__(self, config_path="config.txt"):
        cfg = load_config(config_path)
        self.api_url = cfg.get("API_URL", "https://services.nvd.nist.gov/rest/json/cves/2.0")
        self.max_threads = int(cfg.get("MAX_THREADS", 20))
        self.timeout = int(cfg.get("TIMEOUT", 10))
        self.retries = int(cfg.get("RETRIES", 3))
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
        }
        # init cache
        self._init_db()

    def _init_db(self):
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS cve_cache (
                cve_id TEXT PRIMARY KEY,
                json TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
        conn.close()

    def _get_cached(self, cve_id):
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("SELECT json FROM cve_cache WHERE cve_id = ?", (cve_id,))
        row = cur.fetchone()
        conn.close()
        if row:
            return json.loads(row[0])
        return None

    def _set_cache(self, cve_id, data):
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("REPLACE INTO cve_cache (cve_id, json) VALUES (?, ?)", (cve_id, json.dumps(data, ensure_ascii=False)))
        conn.commit()
        conn.close()

    def search_cves(self, service: str) -> List[Dict]:
        """Busca CVEs por palabra clave (service). Devuelve lista de dicts."""
        url = f"{self.api_url}?keywordSearch={service}"
        resp = safe_get(url, headers=self.headers, retries=self.retries, timeout=self.timeout)
        if not resp:
            return []

        try:
            data = resp.json()
        except ValueError:
            return []

        results = []
        for vuln in data.get("vulnerabilities", []):
            try:
                cve_id = vuln["cve"]["id"]
                descriptions = vuln["cve"].get("descriptions", [])
                # buscar español, si no existe usar inglés
                description = next((d["value"] for d in descriptions if d.get("lang") == "es"), None) \
                              or next((d["value"] for d in descriptions if d.get("lang") == "en"), None) \
                              or "No disponible"
                item = {"cve_id": cve_id, "description": description}
                results.append(item)
            except KeyError:
                continue

        # Ahora obtener detalles (cvss + url) en paralelo, respetando cache
        with ThreadPoolExecutor(max_workers=min(self.max_threads, 20)) as executor:
            futures = {executor.submit(self._enrich_cve, c): c for c in results}
            for fut in as_completed(futures):
                pass  # la función modifica el dict en sitio
        return results

    def _enrich_cve(self, cve_info):
        """Agrega cvss (float) y url. Intenta cache."""
        cve_id = cve_info.get("cve_id")
        if not cve_id:
            return
        cached = self._get_cached(cve_id)
        if cached:
            cve_info.update(cached)
            return

        url = f"https://www.cvedetails.com/cve/{cve_id}/"
        resp = safe_get(url, headers=self.headers, retries=self.retries, timeout=self.timeout)
        cvss_val = "No disponible"
        if resp:
            soup = BeautifulSoup(resp.content, "lxml")
            # varios sitios usan 'cvssbox' o span con class cvss
            cvssbox = soup.find(class_="cvssbox") or soup.find(class_="cvss")
            if cvssbox:
                text = cvssbox.get_text().strip()
                # extraer número
                import re
                m = re.search(r"(\d+(?:\.\d+)?)", text)
                if m:
                    cvss_val = float(m.group(1))
                else:
                    cvss_val = text
        # guardar detalles
        details = {"cvss": cvss_val, "url": url}
        cve_info.update(details)
        # set cache (guardar incluso si cvss "No disponible")
        try:
            self._set_cache(cve_id, details)
        except Exception:
            pass

    def pretty_print(self, cves_details: List[Dict]):
        console = Console()
        table = Table(title="Vulnerabilidades encontradas")

        table.add_column("CVE ID", style="cyan", no_wrap=True)
        table.add_column("Description", style="magenta")
        table.add_column("CVSS", style="green", justify="right")
        table.add_column("URL", style="blue")

        # Ordenar por CVSS descendente (null -> 0)
        def cvss_key(x):
            v = x.get("cvss", 0)
            try:
                return float(v)
            except Exception:
                return 0.0

        cves_sorted = sorted(cves_details, key=cvss_key, reverse=True)

        for c in cves_sorted:
            cvss_display = str(c.get("cvss")) if c.get("cvss") != "No disponible" else "No disponible"
            table.add_row(
                c.get("cve_id", "No disponible"),
                (c.get("description") or "No disponible")[:200],  # cortar descripción larga
                cvss_display,
                c.get("url", "No disponible"),
                end_section=True
            )
        console.print(table)
